{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jyang/CFG/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from model import createModel\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(img_pth, size, method):\n",
    "  \"\"\"\n",
    "    Load images and labels\n",
    "      - benign : 0\n",
    "      - mirai : 1\n",
    "  \"\"\"\n",
    "\n",
    "  images = list()\n",
    "  labels = list()\n",
    "  # save_data = os.path.join('/home/jyang/experiment-new/model', f'image_data_{str(size[0])}')\n",
    "  save_data = os.path.join(img_pth, f'image_data_{str(size[0])}')\n",
    "  print('save_data: ', save_data)\n",
    "  if os.path.isfile(save_data+'.npz'):\n",
    "    print(f'\\033[36;1m[*] File already exists, reading in progress\\033[0m')\n",
    "    data = np.load(save_data+'.npz')\n",
    "    images = data['images']\n",
    "    labels = data['labels']\n",
    "  else:\n",
    "    print(f'\\033[36;1m[*] File does not exist, initialization in progress\\033[0m')\n",
    "    data_path = list()\n",
    "    data_path_b = os.path.join(img_pth, f'benignware_selected_{method}_{str(size[0])}_L')\n",
    "    data_path_m = os.path.join(img_pth, f'linuxmal_selected_{method}_{str(size[0])}_L')\n",
    "    data_path.append([data_path_b, 0])\n",
    "    data_path.append([data_path_m, 1])\n",
    "\n",
    "    for pth in data_path:\n",
    "      print(f'\\033[33;1mdata_path: {pth[0]}, label: {pth[1]}\\033[0m')\n",
    "      for filename in os.listdir(pth[0]):\n",
    "        if not filename.endswith('.png'):\n",
    "          continue\n",
    "        image_path = os.path.join(pth[0], filename)\n",
    "        image = Image.open(image_path).convert('L')\n",
    "        image = np.array(image)/255.0 # preprocessing\n",
    "        images.append(image)\n",
    "        # labels.append([pth[1]])\n",
    "        labels.append(pth[1])\n",
    "    np.savez(save_data, images=images, labels=labels)\n",
    "\n",
    "  return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Shuffle and split data into training and testing sets\n",
    "# def train_test_split(images, labels, test_size=0.2):\n",
    "#   \"\"\"\n",
    "#     Split trai test data\n",
    "#   \"\"\"\n",
    "#   data = list(zip(images, labels))\n",
    "#   random.shuffle(data)\n",
    "#   train_data = data[:int(len(data) * (1 - test_size))]\n",
    "#   test_data = data[int(len(data) * (1 - test_size)):]\n",
    "#   return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(images, labels, test_size=0.2):\n",
    "  \"\"\"\n",
    "    Split train test data\n",
    "  \"\"\"\n",
    "  data = list(zip(images, labels))\n",
    "  random.shuffle(data)\n",
    "  train_data = data[:int(len(data) * (1 - test_size))]\n",
    "  test_data = data[int(len(data) * (1 - test_size)):]\n",
    "  x_train, y_train = zip(*train_data)\n",
    "  x_test, y_test = zip(*test_data)\n",
    "  return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_round(n):\n",
    "  return int(n + 0.5) if n >= 0.5 else int(n - 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NVIDIA GeForce RTX 2080 Ti', 'NVIDIA GeForce RTX 2080 Ti']\n"
     ]
    }
   ],
   "source": [
    "available_gpus = [torch.cuda.get_device_name(i) for i in range(torch.cuda.device_count())]\n",
    "print(available_gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m[+] Confirm GPU \u001b[0m\n",
      "GPU: True\t#num: 2\n",
      "GPU name: ['NVIDIA GeForce RTX 2080 Ti', 'NVIDIA GeForce RTX 2080 Ti']\n",
      "\n",
      "\u001b[32;1m[+] Load data \u001b[0m\n",
      "pth:  /media/islab/media_1/jyang/dataset_20220718/img_data\n",
      "save_data:  /media/islab/media_1/jyang/dataset_20220718/img_data/image_data_128\n",
      "\u001b[36;1m[*] File already exists, reading in progress\u001b[0m\n",
      "images:  20000 \tlabels:  20000\n",
      "\n",
      "\u001b[32;1m[+] Split train test data \u001b[0m\n",
      "y_train: 16000, y_test: 4000\n",
      "\n",
      "\u001b[32;1m[+] Load model \u001b[0m\n",
      "\n",
      "\u001b[32;1m[+] Defined loss functions and optimizers \u001b[0m\n",
      "criterion:  BCELoss() \toptimizer:  SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    foreach: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "\n",
      "\u001b[32;1m[+] Converting Data to PyTorch's Tensor \u001b[0m\n",
      "\n",
      "\u001b[32;1m[+] Putting training data into the GPU \u001b[0m\n",
      "model:\n",
      " createModel(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=16384, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=1, bias=True)\n",
      "    (3): Sigmoid()\n",
      "  )\n",
      ")\n",
      "\n",
      "\u001b[32;1m[+] Create DataLoader \u001b[0m\n",
      "\n",
      "\u001b[32;1m[+] Start Training \u001b[0m\n",
      "Epoch [1/10] - 2.24s - loss: 0.1006 - accuracy: 0.9685 - val_loss: 0.1017 - val_accuracy: 0.9692\n",
      "Epoch [2/10] - 1.37s - loss: 0.0676 - accuracy: 0.9747 - val_loss: 0.0750 - val_accuracy: 0.9715\n",
      "Epoch [3/10] - 1.37s - loss: 0.0468 - accuracy: 0.9846 - val_loss: 0.0602 - val_accuracy: 0.9789\n",
      "Epoch [4/10] - 1.37s - loss: 0.0234 - accuracy: 0.9956 - val_loss: 0.0389 - val_accuracy: 0.9906\n",
      "Epoch [5/10] - 1.38s - loss: 0.0313 - accuracy: 0.9921 - val_loss: 0.0503 - val_accuracy: 0.9834\n",
      "Epoch [6/10] - 1.38s - loss: 0.0118 - accuracy: 0.9974 - val_loss: 0.0292 - val_accuracy: 0.9923\n",
      "Epoch [7/10] - 1.38s - loss: 0.0107 - accuracy: 0.9979 - val_loss: 0.0295 - val_accuracy: 0.9898\n",
      "Epoch [8/10] - 1.38s - loss: 0.0083 - accuracy: 0.9992 - val_loss: 0.0277 - val_accuracy: 0.9913\n",
      "Epoch [9/10] - 1.38s - loss: 0.0105 - accuracy: 0.9973 - val_loss: 0.0369 - val_accuracy: 0.9896\n",
      "Epoch [10/10] - 1.38s - loss: 0.0039 - accuracy: 0.9996 - val_loss: 0.0246 - val_accuracy: 0.9926\n",
      "\n",
      "\u001b[32;1m[+] Save model \u001b[0m\n",
      "model_pth:  /home/jyang/experiment-new/model/model_128.pth\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "  # Confirm GPU\n",
    "  print(f'\\033[32;1m[+] Confirm GPU \\033[0m')\n",
    "  print(f'GPU: {torch.cuda.is_available()}\\t#num: {torch.cuda.device_count()}')\n",
    "  available_gpus = [torch.cuda.get_device_name(i) for i in range(torch.cuda.device_count())]\n",
    "  print(f'GPU name: {available_gpus}')\n",
    "\n",
    "  # Load data\n",
    "  print(f'\\n\\033[32;1m[+] Load data \\033[0m')\n",
    "  pth = '/media/islab/media_1/jyang/dataset_20220718/img_data'\n",
    "  print('pth: ', pth)\n",
    "  SIZE = (128, 128)\n",
    "  # SIZE = (256, 256)\n",
    "  images, labels = load_data(pth, SIZE, 'trun')\n",
    "  print('images: ', len(images), '\\tlabels: ', len(labels))\n",
    "\n",
    "  # Split data\n",
    "  print(f'\\n\\033[32;1m[+] Split train test data \\033[0m')\n",
    "  x_train, y_train, x_test, y_test = train_test_split(images, labels)\n",
    "  print(f'y_train: {len(y_train)}, y_test: {len(y_test)}')  # 0: image    1: label \n",
    "\n",
    "  # Load model\n",
    "  print(f'\\n\\033[32;1m[+] Load model \\033[0m')\n",
    "  # INPUT_SHAPE = (128, 128, 1)\n",
    "  # INPUT_SHAPE = (256, 256, 1)\n",
    "  model = createModel()  # Build the model\n",
    "  # print('model:\\n', model)\n",
    "\n",
    "  # Defined loss functions and optimizers\n",
    "  print(f'\\n\\033[32;1m[+] Defined loss functions and optimizers \\033[0m')\n",
    "  criterion = nn.BCELoss()\n",
    "  optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "  print('criterion: ', criterion, '\\toptimizer: ', optimizer)\n",
    "\n",
    "  # Converting Data to PyTorch's Tensor\n",
    "  print(f'\\n\\033[32;1m[+] Converting Data to PyTorch\\'s Tensor \\033[0m')\n",
    "  x_train = torch.Tensor(np.array(x_train))\n",
    "  y_train = torch.Tensor(np.array(y_train)).unsqueeze(1)  # unsqueeze(1): Insert a dimension into the tensor and add a dimension to it\n",
    "  x_train = x_train.view(-1, 1, SIZE[0], SIZE[1])\n",
    "  x_test = torch.Tensor(np.array(x_test))\n",
    "  y_test = torch.Tensor(np.array(y_test)).unsqueeze(1)\n",
    "  x_test = x_test.view(-1, 1, SIZE[0], SIZE[1])\n",
    "\n",
    "  # Putting training data into the GPU\n",
    "  print(f'\\n\\033[32;1m[+] Putting training data into the GPU \\033[0m')\n",
    "  x_train = x_train.to('cuda')\n",
    "  y_train = y_train.to('cuda')\n",
    "  x_test = x_test.to('cuda')\n",
    "  y_test = y_test.to('cuda')\n",
    "  model.to('cuda')\n",
    "  print('model:\\n', model)\n",
    "\n",
    "  # Create DataLoader\n",
    "  print(f'\\n\\033[32;1m[+] Create DataLoader \\033[0m')\n",
    "  train_dataset = TensorDataset(x_train, y_train)\n",
    "  train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "  test_dataset = TensorDataset(x_test, y_test)\n",
    "  test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "  # Start Training\n",
    "  print(f'\\n\\033[32;1m[+] Start Training \\033[0m')\n",
    "  num_epochs = 10\n",
    "  loss_history = []\n",
    "  acc_history = []\n",
    "  for epoch in range(num_epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    for x_batch, y_batch in train_dataloader:\n",
    "      x_batch = x_batch.to('cuda')\n",
    "      y_batch = y_batch.to('cuda')\n",
    "\n",
    "      optimizer.zero_grad() # Zero the gradients\n",
    "      outputs = model(x_batch)  # Forward pass\n",
    "      loss = criterion(outputs, y_batch)\n",
    "      loss.backward() # Backward pass and optimization\n",
    "      optimizer.step()\n",
    "      running_loss += loss.item()\n",
    "    epoch_end_time = time.time()\n",
    "    epoch_duration = epoch_end_time - epoch_start_time\n",
    "\n",
    "    # Calculate the Loss and Accuracy on the training data\n",
    "    model.eval()\n",
    "    train_loss, train_acc = 0.0, 0.0\n",
    "    for x_batch, y_batch in train_dataloader:\n",
    "      x_batch = x_batch.to('cuda')\n",
    "      y_batch = y_batch.to('cuda')\n",
    "      outputs = model(x_batch)\n",
    "      loss = criterion(outputs, y_batch)\n",
    "      train_loss += loss.item()\n",
    "      train_acc += (outputs.round() == y_batch).float().mean()\n",
    "    train_loss /= len(train_dataloader)\n",
    "    train_acc /= len(train_dataloader)\n",
    "    loss_history.append(train_loss)\n",
    "    acc_history.append(train_acc.cpu().numpy())\n",
    "\n",
    "    # Calculating Loss and Accuracy on Validation Data\n",
    "    val_loss, val_acc = 0.0, 0.0\n",
    "    with torch.no_grad():\n",
    "      for x_batch, y_batch in test_dataloader:\n",
    "        x_batch = x_batch.to('cuda')\n",
    "        y_batch = y_batch.to('cuda')\n",
    "        outputs = model(x_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        val_loss += loss.item()\n",
    "        val_acc += (outputs.round() == y_batch).float().mean()\n",
    "    val_loss /= len(test_dataloader)\n",
    "    val_acc /= len(test_dataloader)\n",
    "  \n",
    "    # Print loss and accuracy\n",
    "    print('Epoch [{}/{}] - {:.2f}s - loss: {:.4f} - accuracy: {:.4f} - val_loss: {:.4f} - val_accuracy: {:.4f}'.format(\n",
    "              epoch + 1, num_epochs, epoch_duration, train_loss, train_acc, val_loss, val_acc))\n",
    "  \n",
    "  # Save model\n",
    "  print(f'\\n\\033[32;1m[+] Save model \\033[0m')\n",
    "  model_pth = os.path.join('/home/jyang/experiment-new/model', f'model_{str(SIZE[0])}.pth')\n",
    "  print('model_pth: ', model_pth)\n",
    "  torch.save(model.state_dict(), model_pth)\n",
    "  \n",
    "  # Plot loss and accuracy curves\n",
    "  plt.plot(loss_history, label='loss')\n",
    "  plt.plot(acc_history, label='accuracy')\n",
    "  plt.legend()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x_batch, y_batch in test_dataloader:\n",
    "#   with torch.no_grad():\n",
    "#     test_output = model(x_batch)\n",
    "#     pred = torch.round(test_output)\n",
    "#     print(\"pred: \", test_output>0.5)\n",
    "#     print(\"y_batch: \", y_batch)\n",
    "#   break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add add mov push push mov push push\n",
      "and xor jmp mov mov mov\n",
      "pop add sub mov add jmp add add mov add mov sub\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    \"add add mov push push mov push push\",\n",
    "    \"and xor jmp mov mov mov\",\n",
    "    \"pop add sub mov add jmp add add mov add mov sub\",\n",
    "]\n",
    "text = \"\\n\".join(data)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opcodes = [\n",
    "  [\"add add\", \"mov\", \"push push mov push push\"],\n",
    "  [\"and xor\", \"jmp\"],\n",
    "  [\"pop\", \"add sub\", \"mov add jmp\", \"add add\", \"mov add mov sub\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['add add', 'mov', 'push push mov push push'], ['and xor', 'jmp', 'mov mov mov'], ['sub add pop', 'jmp add mov', 'add add', 'mov add mov sub']]\n"
     ]
    }
   ],
   "source": [
    "opcodes = [    \n",
    "  [\"push push mov push push\", \"mov\", \"add add\"],\n",
    "  [\"mov mov mov\", \"jmp\", \"and xor\"],\n",
    "  [\"mov add mov sub\", \"add add\", \"jmp add mov\", \"sub add pop\"],\n",
    "]\n",
    "\n",
    "# 反轉每一筆資料\n",
    "for i in range(len(opcodes)):\n",
    "  opcodes[i] = opcodes[i][::-1]\n",
    "print(opcodes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CFG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0534e0d037b30c5540ced1cc1ccf63837d4a21f9dbf08c755df9255305f76dfd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
